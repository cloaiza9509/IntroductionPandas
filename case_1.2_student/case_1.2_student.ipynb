{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How are trading volume and volatility related for energy stocks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "By the end of this case, we will have introduced the `pandas` library within Python. You will also have gained experience with the `numpy` library, know how to read data files, and conduct descriptive statistics.\n",
    "\n",
    "You should also begin to develop a proper mindset for investigating the library on your own, via documentation or other resources such as StackOverflow. Self-research of existing documentation is a crucial part of developing as a data professional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Business Context.** You are an analyst at a large bank focused on natural resource stock investments. Natural resources are vital for a variety of industries in our economy. Recently, your division has taken interest in the following stocks:\n",
    "\n",
    "1. Dominion Energy Inc.\n",
    "2. Exelon Corp.\n",
    "3. NextEra Energy Inc.\n",
    "4. Southern Co.\n",
    "5. Duke Energy Corp.\n",
    "\n",
    "These stocks are all part of the energy sector, an important but volatile sector of the stock market. While high volatility increases the chance of great gains, it also makes it more likely to have large losses, so risk must be carefully managed with high-volatility stocks.\n",
    "\n",
    "Because your firm is quite large, there must be enough trading volume (average amount of shares transacted per day) so that it can easily transact in these stocks. Otherwise, this effect compounded with the stocks' naturally high volatility could make these too risky for the bank to invest in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Problem.** Given that both low trading volume and high volatility present risks to your investments, your team lead asks you to investigate the following: **\"How is the volatility of energy stocks related to their average daily trading volume?\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analytical Context.** The data you've been given is in the [Comma Separated Value (CSV) format](https://frictionlessdata.io/docs//), and comprises price and trading volume data for the above stocks. This case begins with a brief overview of this data, after which you will: (1) learn how to use the Python library [pandas](https://towardsdatascience.com/a-quick-introduction-to-the-pandas-python-library-f1b678f34673) to load the data; (2) use ```pandas``` transform this data into a form amenable for analysis; and finally (3) use ```pandas``` to analyze the above question and come to a conclusion. As you may have guessed, ```pandas``` is an enormously useful library for data analysis and manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages to aid in data analysis\n",
    "\n",
    "[External libraries (a.k.a. packages)](https://www.learnpython.org/en/Modules_and_Packages) are code bases that contain a variety of pre-written functions and tools. This allows you to perform a variety of complex tasks in Python without having to \"reinvent the wheel\" build everything from the ground up. We will use two core packages: ```pandas``` and ```numpy```.\n",
    "\n",
    "```pandas``` is an external library that provides functionality for data analysis. Pandas specifically offers a variety of data structures and data manipulation methods that allow you to perform complex tasks with simple, one-line commands.\n",
    "\n",
    "```numpy``` is a package that we will use later in the case that offers numerous mathematical operations. Together, [pandas](https://pandas.pydata.org/pandas-docs/stable/whatsnew/v1.0.0.html) and [numpy](https://numpy.org/) allow you to create a data science workflow within Python. `numpy` is in many ways foundational to `pandas`, providing vectorized operations, while `pandas` provides higher level abstractions built on top of `numpy`.</font>\n",
    "\n",
    "Let's import both packages using the ```import``` keyword. We will rename ```pandas``` to ```pd``` and ```numpy``` to ```np``` using the ```as``` keyword. This allows us to use the short name abbreviation when we want to reference any function that is inside either package. The abbreviations we chose are standard across the data science industry and should be followed unless there is a very good reason not to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Import the NumPy package\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that these packages are loaded into Python, we can use their contents. Let's first take a look at ```pandas``` as it has a variety of features we will use to load and analyze our stock data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamentals of ```pandas```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`pandas` is a Python library that facilitates a wide range of data analysis and manipulation. Before, you saw basic data structures in Python such as lists and dictionaries. While you can build a basic data table (similar to an Excel spreadsheet) using nested lists in Python, they get quite difficult to work with. By contrast, in `pandas` the table data structure, known as a `DataFrame`, is a first-class citizen and you can easily manipulate your data thinking of it in rows and columns.\n",
    "\n",
    "If you've ever used or heard of R or SQL before, `pandas` brings some functionality from each of these to Python, allowing you to structure and filter data more efficiently than pure Python. This efficiency is seen in two distinct ways:\n",
    "\n",
    "* Scripts written using `pandas` will often run faster than scripts written in pure Python\n",
    "* Scripts written using `pandas` will often contain far fewer lines of code than the equivalent script written in pure Python.\n",
    "\n",
    "At the core of the ```pandas``` library are two fundamental data structures/objects:\n",
    "1. [Series](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html)\n",
    "2. [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)\n",
    "\n",
    "A ```Series``` object stores single-column data along with an **index**. An index is just a way of \"numbering\" the ```Series``` object. For example, in this case study, the indices will be dates, while the single-column data may be stock prices or daily trading volume.\n",
    "\n",
    "A ```DataFrame``` object is a two-dimensional tabular data structure with labeled axes. It is conceptually helpful to think of a DataFrame object as a collection of Series objects. Namely, think of each column in a DataFrame as a single Series object, where each of these Series objects shares a common index -  the index of the DataFrame object.\n",
    "\n",
    "Below is the syntax for creating a Series object, followed by the syntax for creating a DataFrame object. Note that DataFrame objects can also have a single-column â€“ think of this as a DataFrame consisting of a single Series object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1000\n",
       "1     2600\n",
       "2     1524\n",
       "3    98000\n",
       "Name: Volume, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a simple Series object\n",
    "simple_series = pd.Series(\n",
    "    index=[0, 1, 2, 3], name=\"Volume\", data=[1000, 2600, 1524, 98000]\n",
    ")\n",
    "simple_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By changing ```pd.Series``` to ```pd.DataFrame```, and adding a columns input list, a DataFrame object can be created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Volume\n",
       "0    1000\n",
       "1    2600\n",
       "2    1524\n",
       "3   98000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a simple DataFrame object\n",
    "simple_df = pd.DataFrame(\n",
    "    index=[0, 1, 2, 3], columns=[\"Volume\"], data=[1000, 2600, 1524, 98000]\n",
    ")\n",
    "simple_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame objects are more general than Series objects, and one DataFrame can hold many Series objects, each as a different column. Let's create a two-column DataFrame object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190101</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20190102</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20190103</td>\n",
       "      <td>1524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190104</td>\n",
       "      <td>98000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date  Volume\n",
       "0  20190101    1000\n",
       "1  20190102    2600\n",
       "2  20190103    1524\n",
       "3  20190104   98000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create another DataFrame object\n",
    "another_df = pd.DataFrame(\n",
    "    index=[0, 1, 2, 3],\n",
    "    columns=[\"Date\", \"Volume\"],\n",
    "    data=[[20190101, 1000], [20190102, 2600], [20190103, 1524], [20190104, 98000]],\n",
    ")\n",
    "another_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how a list of lists was used to specify the data in the ```another_df``` DataFrame. Each element of the list corresponds to a row in the DataFrame, so the list has 4 elements because there are 4 indices. Each element of the list of lists has 2 elements because the DataFrame has two columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using <code>pandas</code> to analyze stock data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Recall that we have CSV files that include data for each of the following stocks:\n",
    "\n",
    "1. Dominion Energy Inc. (Stock Symbol: D)\n",
    "2. Exelon Corp. (Stock Symbol: EXC)\n",
    "3. NextEra Energy Inc. (Stock Symbol: NEE)\n",
    "4. Southern Co. (Stock Symbol: SO)\n",
    "5. Duke Energy Corp. (Stock Symbol: DUK)\n",
    "\n",
    "The available data for each stock includes:\n",
    "\n",
    "1. **Date:** The day of the year\n",
    "2. **Open:** The stock opening price of the day\n",
    "3. **High:** The highest observed stock price of the day\n",
    "4. **Low:** The lowest observed stock price of the day\n",
    "5. **Close:** The stock closing price of the day\n",
    "6. **Adj Close:** The adjusted stock closing price for the day (adjusted for splits and dividends)\n",
    "7. **Volume:** The volume of the stock traded over the day\n",
    "\n",
    "To get a better sense of the available data, let's first take a look at just the data for Dominion Energy, listed on the New York Stock Exchange under the symbol D. You are given a CSV file that contains the company's stock data, ```D.```. `pandas` allows easy loading of CSV files through the use of the method [pd.read_csv()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load a file as a DataFrame and assign to df\n",
    "df = pd.read_csv(\"data/D.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of the file ```D.``` are now stored in the DataFrame object ```df```.\n",
    "\n",
    "There are several common methods and attributes available to take a peek at the data and get a sense of it:\n",
    "\n",
    "1. ```DataFrame.head()```  -> returns the column names and first 5 rows by default\n",
    "2. ```DataFrame.tail()```  -> returns the column names and last 5 rows by default\n",
    "3. ```DataFrame.shape```   -> returns (num_rows, num_columns)\n",
    "4. ```DataFrame.columns``` -> returns index of columns\n",
    "5. ```DataFrame.index```   -> returns index of rows\n",
    "\n",
    "In your spare time please check the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/) and explore the parameters of these methods as well as other methods. Familiarity with this library will dramatically improve your productivity as a data scientist.\n",
    "\n",
    "Using ```df.head()``` and ```df.tail()``` we can take a look at the data contents. Unless specified otherwise, Series and DataFrame objects have indices starting at 0 and increase monotonically upward along the integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-28</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>71.059998</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>70.879997</td>\n",
       "      <td>57.963978</td>\n",
       "      <td>1806400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-29</td>\n",
       "      <td>70.669998</td>\n",
       "      <td>70.980003</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>57.187099</td>\n",
       "      <td>2231100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.660004</td>\n",
       "      <td>68.400002</td>\n",
       "      <td>68.970001</td>\n",
       "      <td>56.402020</td>\n",
       "      <td>2588900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>68.629997</td>\n",
       "      <td>68.849998</td>\n",
       "      <td>67.580002</td>\n",
       "      <td>67.639999</td>\n",
       "      <td>55.314388</td>\n",
       "      <td>3266900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>67.330002</td>\n",
       "      <td>68.410004</td>\n",
       "      <td>67.220001</td>\n",
       "      <td>67.589996</td>\n",
       "      <td>55.273487</td>\n",
       "      <td>2601800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close   Volume\n",
       "0  2014-07-28  69.750000  71.059998  69.750000  70.879997  57.963978  1806400\n",
       "1  2014-07-29  70.669998  70.980003  69.930000  69.930000  57.187099  2231100\n",
       "2  2014-07-30  70.000000  70.660004  68.400002  68.970001  56.402020  2588900\n",
       "3  2014-07-31  68.629997  68.849998  67.580002  67.639999  55.314388  3266900\n",
       "4  2014-08-01  67.330002  68.410004  67.220001  67.589996  55.273487  2601800"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the head of the DataFrame (i.e. the top rows of the DataFrame)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>76.879997</td>\n",
       "      <td>76.930000</td>\n",
       "      <td>75.779999</td>\n",
       "      <td>76.260002</td>\n",
       "      <td>76.260002</td>\n",
       "      <td>2956500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>76.099998</td>\n",
       "      <td>76.199997</td>\n",
       "      <td>75.269997</td>\n",
       "      <td>75.430000</td>\n",
       "      <td>75.430000</td>\n",
       "      <td>3175600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>75.660004</td>\n",
       "      <td>75.720001</td>\n",
       "      <td>74.889999</td>\n",
       "      <td>75.180000</td>\n",
       "      <td>75.180000</td>\n",
       "      <td>3101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2019-07-25</td>\n",
       "      <td>75.150002</td>\n",
       "      <td>75.430000</td>\n",
       "      <td>74.610001</td>\n",
       "      <td>74.860001</td>\n",
       "      <td>74.860001</td>\n",
       "      <td>3417200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>74.730003</td>\n",
       "      <td>75.349998</td>\n",
       "      <td>74.610001</td>\n",
       "      <td>75.150002</td>\n",
       "      <td>75.150002</td>\n",
       "      <td>3076500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Open       High        Low      Close  Adj Close  \\\n",
       "1254  2019-07-22  76.879997  76.930000  75.779999  76.260002  76.260002   \n",
       "1255  2019-07-23  76.099998  76.199997  75.269997  75.430000  75.430000   \n",
       "1256  2019-07-24  75.660004  75.720001  74.889999  75.180000  75.180000   \n",
       "1257  2019-07-25  75.150002  75.430000  74.610001  74.860001  74.860001   \n",
       "1258  2019-07-26  74.730003  75.349998  74.610001  75.150002  75.150002   \n",
       "\n",
       "       Volume  \n",
       "1254  2956500  \n",
       "1255  3175600  \n",
       "1256  3101900  \n",
       "1257  3417200  \n",
       "1258  3076500  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the tail of the DataFrame (i.e. the top rows of the DataFrame)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we see there are 1259 data entries (each with 7 data points) for Dominion Energy. The shape of a DataFrame is accessed using the ```shape``` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1259, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the shape of the two-dimensional structure, that is (num_rows, num_columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that ```DataFrame.columns``` and ```DataFrame.index``` return an index object instead of a list. To cast an index to a list for further list manipulation, we use the ```list()``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of the column names of the DataFrame\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of the column names of the DataFrame\n",
    "list(df.index)[0:20]  # only showing first 20 index values so reduce screen output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating additional variables relevant to stock volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oftentimes, the data provided to you will not be sufficient to achieve your goal. You may have to add additional variables or data features to assist you. Recall that our original question concerned the relationship between stock trading volume and volatility. Therefore, our DataFrame must have features related to both of these quantities.\n",
    "\n",
    "It can be helpful to think about adding columns to DataFrames as adding adjacent columns one-by-one in Excel. Here is an example of how to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-28</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>71.059998</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>70.879997</td>\n",
       "      <td>57.963978</td>\n",
       "      <td>1806400</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-29</td>\n",
       "      <td>70.669998</td>\n",
       "      <td>70.980003</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>57.187099</td>\n",
       "      <td>2231100</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.660004</td>\n",
       "      <td>68.400002</td>\n",
       "      <td>68.970001</td>\n",
       "      <td>56.402020</td>\n",
       "      <td>2588900</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>68.629997</td>\n",
       "      <td>68.849998</td>\n",
       "      <td>67.580002</td>\n",
       "      <td>67.639999</td>\n",
       "      <td>55.314388</td>\n",
       "      <td>3266900</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>67.330002</td>\n",
       "      <td>68.410004</td>\n",
       "      <td>67.220001</td>\n",
       "      <td>67.589996</td>\n",
       "      <td>55.273487</td>\n",
       "      <td>2601800</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close   Volume  \\\n",
       "0  2014-07-28  69.750000  71.059998  69.750000  70.879997  57.963978  1806400   \n",
       "1  2014-07-29  70.669998  70.980003  69.930000  69.930000  57.187099  2231100   \n",
       "2  2014-07-30  70.000000  70.660004  68.400002  68.970001  56.402020  2588900   \n",
       "3  2014-07-31  68.629997  68.849998  67.580002  67.639999  55.314388  3266900   \n",
       "4  2014-08-01  67.330002  68.410004  67.220001  67.589996  55.273487  2601800   \n",
       "\n",
       "  Symbol  \n",
       "0      D  \n",
       "1      D  \n",
       "2      D  \n",
       "3      D  \n",
       "4      D  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new column named \"Symbol\"\n",
    "df[\"Symbol\"] = \"D\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1806400\n",
       "1    2231100\n",
       "2    2588900\n",
       "3    3266900\n",
       "4    2601800\n",
       "Name: Volume, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can access a column by using [] brackets and the column name\n",
    "df['Volume'].head() # added .head() to suppress output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Volume_Millions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-28</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>71.059998</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>70.879997</td>\n",
       "      <td>57.963978</td>\n",
       "      <td>1806400</td>\n",
       "      <td>D</td>\n",
       "      <td>1.8064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-29</td>\n",
       "      <td>70.669998</td>\n",
       "      <td>70.980003</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>57.187099</td>\n",
       "      <td>2231100</td>\n",
       "      <td>D</td>\n",
       "      <td>2.2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.660004</td>\n",
       "      <td>68.400002</td>\n",
       "      <td>68.970001</td>\n",
       "      <td>56.402020</td>\n",
       "      <td>2588900</td>\n",
       "      <td>D</td>\n",
       "      <td>2.5889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>68.629997</td>\n",
       "      <td>68.849998</td>\n",
       "      <td>67.580002</td>\n",
       "      <td>67.639999</td>\n",
       "      <td>55.314388</td>\n",
       "      <td>3266900</td>\n",
       "      <td>D</td>\n",
       "      <td>3.2669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>67.330002</td>\n",
       "      <td>68.410004</td>\n",
       "      <td>67.220001</td>\n",
       "      <td>67.589996</td>\n",
       "      <td>55.273487</td>\n",
       "      <td>2601800</td>\n",
       "      <td>D</td>\n",
       "      <td>2.6018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close   Volume  \\\n",
       "0  2014-07-28  69.750000  71.059998  69.750000  70.879997  57.963978  1806400   \n",
       "1  2014-07-29  70.669998  70.980003  69.930000  69.930000  57.187099  2231100   \n",
       "2  2014-07-30  70.000000  70.660004  68.400002  68.970001  56.402020  2588900   \n",
       "3  2014-07-31  68.629997  68.849998  67.580002  67.639999  55.314388  3266900   \n",
       "4  2014-08-01  67.330002  68.410004  67.220001  67.589996  55.273487  2601800   \n",
       "\n",
       "  Symbol  Volume_Millions  \n",
       "0      D           1.8064  \n",
       "1      D           2.2311  \n",
       "2      D           2.5889  \n",
       "3      D           3.2669  \n",
       "4      D           2.6018  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new column named \"Volume_Millions\", which is calculated from the Volume column currently in df\n",
    "# divide every row in df['Volume'] by 1 million, store in new column\n",
    "df[\"Volume_Millions\"] = df[\"Volume\"] / 1000000.0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1259, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the updated DataFrame shape. Two new columns have been added.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed, we need to have a feature in our DataFrame that is related to volatility. Because this currently does not exist, we must create it from the already available features. Recall that volatility is the standard deviation of daily returns over a period of time, so let's create a feature for daily returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"VolStat\"] = (df[\"High\"] - df[\"Low\"]) / df[\"Open\"]\n",
    "df[\"Return\"] = (df[\"Close\"] / df[\"Open\"]) - 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the power of ```pandas```. We can simply perform mathematical operations on columns of DataFrames just as if the DataFrames were single variables themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Volume_Millions</th>\n",
       "      <th>VolStat</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-28</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>71.059998</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>70.879997</td>\n",
       "      <td>57.963978</td>\n",
       "      <td>1806400</td>\n",
       "      <td>D</td>\n",
       "      <td>1.8064</td>\n",
       "      <td>0.018781</td>\n",
       "      <td>0.016201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-29</td>\n",
       "      <td>70.669998</td>\n",
       "      <td>70.980003</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>57.187099</td>\n",
       "      <td>2231100</td>\n",
       "      <td>D</td>\n",
       "      <td>2.2311</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>-0.010471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.660004</td>\n",
       "      <td>68.400002</td>\n",
       "      <td>68.970001</td>\n",
       "      <td>56.402020</td>\n",
       "      <td>2588900</td>\n",
       "      <td>D</td>\n",
       "      <td>2.5889</td>\n",
       "      <td>0.032286</td>\n",
       "      <td>-0.014714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>68.629997</td>\n",
       "      <td>68.849998</td>\n",
       "      <td>67.580002</td>\n",
       "      <td>67.639999</td>\n",
       "      <td>55.314388</td>\n",
       "      <td>3266900</td>\n",
       "      <td>D</td>\n",
       "      <td>3.2669</td>\n",
       "      <td>0.018505</td>\n",
       "      <td>-0.014425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>67.330002</td>\n",
       "      <td>68.410004</td>\n",
       "      <td>67.220001</td>\n",
       "      <td>67.589996</td>\n",
       "      <td>55.273487</td>\n",
       "      <td>2601800</td>\n",
       "      <td>D</td>\n",
       "      <td>2.6018</td>\n",
       "      <td>0.017674</td>\n",
       "      <td>0.003861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close   Volume  \\\n",
       "0  2014-07-28  69.750000  71.059998  69.750000  70.879997  57.963978  1806400   \n",
       "1  2014-07-29  70.669998  70.980003  69.930000  69.930000  57.187099  2231100   \n",
       "2  2014-07-30  70.000000  70.660004  68.400002  68.970001  56.402020  2588900   \n",
       "3  2014-07-31  68.629997  68.849998  67.580002  67.639999  55.314388  3266900   \n",
       "4  2014-08-01  67.330002  68.410004  67.220001  67.589996  55.273487  2601800   \n",
       "\n",
       "  Symbol  Volume_Millions   VolStat    Return  \n",
       "0      D           1.8064  0.018781  0.016201  \n",
       "1      D           2.2311  0.014858 -0.010471  \n",
       "2      D           2.5889  0.032286 -0.014714  \n",
       "3      D           3.2669  0.018505 -0.014425  \n",
       "4      D           2.6018  0.017674  0.003861  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have features relevant to the original question, and can proceed to the analysis step. A common first step in data analysis is to learn about the distribution of the available data. We will do this next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning about the data distribution through summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's aggregate summary statistics for the five energy sector companies under study. Fortunately, the DataFrame and Series objects offer a myriad of data summary statistics methods:\n",
    "\n",
    "1. ```min()```\n",
    "2. ```median()```\n",
    "3. ```mean()```\n",
    "4. ```max()```\n",
    "5. ```quantile()```\n",
    "\n",
    "Below, each method is used on the ```Volume_Millions``` column. Notice how simple the functions are to apply to the DataFrame. Simply type the name of the DataFrame, followed by a ```.``` and then the method name you'd like to calculate. We've chosen to select a single column ```Volume_Millions``` from the DataFrame ```df```, but you could have just as easily called these methods on the full DataFrame rather than a single column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7384"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the minimum of the Volume_Millions column\n",
    "df[\"Volume_Millions\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6957"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the median of the Volume_Millions column\n",
    "df[\"Volume_Millions\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0881293089753763"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the average of the Volume_Millions column\n",
    "df[\"Volume_Millions\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.5874"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the maximum of the Volume_Millions column\n",
    "df[\"Volume_Millions\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd also like to explore the data distribution at a more granular level to see how the distribution looks beyond the simple summary statistics presented above. For this, we can use the ```quantile()``` method. The ```quantile()``` method will return the value which represents the given percentile of all the data under study (in this case, of the ```Volume_Millions``` data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0888"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the 25th percentile\n",
    "df['Volume_Millions'].quantile(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.61285"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the 75th percentile\n",
    "df['Volume_Millions'].quantile(0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a more efficient method to quickly compute all of these summary statistics? Yes. One incredibly useful method that combines these summary statistics and also adds a couple others is the [describe()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1259.000000\n",
       "mean        3.088129\n",
       "std         1.548809\n",
       "min         0.738400\n",
       "25%         2.088800\n",
       "50%         2.695700\n",
       "75%         3.612850\n",
       "max        14.587400\n",
       "Name: Volume_Millions, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Volume_Millions'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this distribution analysis of the daily trading volume, we can see that more than 14 million shares would be a very large trading day, whereas below 2 million shares would be a relatively small trading day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to describe, there is a [value_counts() method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) for checking the frequency of elements in categorical data. Please be aware that `value_counts()` is a method of the Series class and NOT the DataFrame class. This means you have to isolate a specific column of a DataFrame before calling `value_counts()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numbers</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   numbers  color\n",
       "0        1    red\n",
       "1        2    red\n",
       "2        3    red\n",
       "3        4   blue\n",
       "4        5   blue\n",
       "5        6  green\n",
       "6        7   blue\n",
       "7        8  green"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_data = {\n",
    "    \"numbers\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    \"color\": [\"red\", \"red\", \"red\", \"blue\", \"blue\", \"green\", \"blue\", \"green\"],\n",
    "}\n",
    "category_df = pd.DataFrame(data=dict_data)\n",
    "\n",
    "category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'value_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-975ef4cde296>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#why doesn't this work? (uncomment the expression that follows)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcategory_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5179\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'value_counts'"
     ]
    }
   ],
   "source": [
    "#why doesn't this work? (uncomment the expression that follows)\n",
    "category_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "red      3\n",
       "blue     3\n",
       "green    2\n",
       "Name: color, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only Series objects can call this method (uncomment the following expression)\n",
    "category_df['color'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "\n",
    "Determine the 25th, 50th, and 75th percentile for the ```Open```, ```High```, ```Low```, and ```Close``` columns of ```df```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1259.000000\n",
      "mean       73.253765\n",
      "std         4.187696\n",
      "min        61.790001\n",
      "25%        70.220001\n",
      "50%        73.180000\n",
      "75%        76.560001\n",
      "max        85.110001\n",
      "Name: Open, dtype: float64\n",
      "count    1259.000000\n",
      "mean       73.780842\n",
      "std         4.162946\n",
      "min        62.840000\n",
      "25%        70.829998\n",
      "50%        73.690002\n",
      "75%        76.954998\n",
      "max        85.300003\n",
      "Name: High, dtype: float64\n",
      "count    1259.000000\n",
      "mean       72.697911\n",
      "std         4.177581\n",
      "min        61.529999\n",
      "25%        69.685001\n",
      "50%        72.550003\n",
      "75%        75.959999\n",
      "max        83.900002\n",
      "Name: Low, dtype: float64\n",
      "count    1259.000000\n",
      "mean       73.274940\n",
      "std         4.182135\n",
      "min        61.750000\n",
      "25%        70.239998\n",
      "50%        73.150002\n",
      "75%        76.510002\n",
      "max        84.910004\n",
      "Name: Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['Open'].describe())\n",
    "print(df['High'].describe())\n",
    "print(df['Low'].describe())\n",
    "print(df['Close'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating data from multiple companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So far, we've only been looking at data from one of our five companies. Let's go ahead and combine all five CSV files to analyze the five companies together. This will also reduce the amount of programming work required since the code will be shared across the five companies.\n",
    "\n",
    "One way to accomplish this aggregation task is to use the [pd.concat()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) method from ```pandas```. An input into this method may be a list of DataFrames that you'd like to concatenate. We will use a `for` loop to loop over each stock symbol, load the corresponding CSV file, and then append the result to a list which is later aggregated using ```pd.concat()```. Let's take a look at how this is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining stock symbols\n",
      " --- Start loop over symbols --- \n",
      "Processing Symbol: D\n",
      "Processing Symbol: EXC\n",
      "Processing Symbol: NEE\n",
      "Processing Symbol: SO\n",
      "Processing Symbol: DUK\n",
      " --- Complete loop over symbols --- \n",
      "\n",
      "Aggregating Data\n",
      "Calculating Salient Features\n",
      "agg_df DataFrame shape (rows, columns): \n",
      "(6295, 11)\n",
      "Head of agg_df DataFrame: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Volume_Millions</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>VolStat</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-28</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>71.059998</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>70.879997</td>\n",
       "      <td>57.963978</td>\n",
       "      <td>1806400</td>\n",
       "      <td>1.8064</td>\n",
       "      <td>D</td>\n",
       "      <td>0.018781</td>\n",
       "      <td>0.016201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-29</td>\n",
       "      <td>70.669998</td>\n",
       "      <td>70.980003</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>57.187099</td>\n",
       "      <td>2231100</td>\n",
       "      <td>2.2311</td>\n",
       "      <td>D</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>-0.010471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.660004</td>\n",
       "      <td>68.400002</td>\n",
       "      <td>68.970001</td>\n",
       "      <td>56.402020</td>\n",
       "      <td>2588900</td>\n",
       "      <td>2.5889</td>\n",
       "      <td>D</td>\n",
       "      <td>0.032286</td>\n",
       "      <td>-0.014714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>68.629997</td>\n",
       "      <td>68.849998</td>\n",
       "      <td>67.580002</td>\n",
       "      <td>67.639999</td>\n",
       "      <td>55.314388</td>\n",
       "      <td>3266900</td>\n",
       "      <td>3.2669</td>\n",
       "      <td>D</td>\n",
       "      <td>0.018505</td>\n",
       "      <td>-0.014425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>67.330002</td>\n",
       "      <td>68.410004</td>\n",
       "      <td>67.220001</td>\n",
       "      <td>67.589996</td>\n",
       "      <td>55.273487</td>\n",
       "      <td>2601800</td>\n",
       "      <td>2.6018</td>\n",
       "      <td>D</td>\n",
       "      <td>0.017674</td>\n",
       "      <td>0.003861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close   Volume  \\\n",
       "0  2014-07-28  69.750000  71.059998  69.750000  70.879997  57.963978  1806400   \n",
       "1  2014-07-29  70.669998  70.980003  69.930000  69.930000  57.187099  2231100   \n",
       "2  2014-07-30  70.000000  70.660004  68.400002  68.970001  56.402020  2588900   \n",
       "3  2014-07-31  68.629997  68.849998  67.580002  67.639999  55.314388  3266900   \n",
       "4  2014-08-01  67.330002  68.410004  67.220001  67.589996  55.273487  2601800   \n",
       "\n",
       "   Volume_Millions Symbol   VolStat    Return  \n",
       "0           1.8064      D  0.018781  0.016201  \n",
       "1           2.2311      D  0.014858 -0.010471  \n",
       "2           2.5889      D  0.032286 -0.014714  \n",
       "3           3.2669      D  0.018505 -0.014425  \n",
       "4           2.6018      D  0.017674  0.003861  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load five  files into one dataframe\n",
    "print(\"Defining stock symbols\")\n",
    "symbol_data_to_load = [\"D\", \"EXC\", \"NEE\", \"SO\", \"DUK\"]\n",
    "list_of_df = []\n",
    "\n",
    "# Loop over all symbols\n",
    "print(\" --- Start loop over symbols --- \")\n",
    "for symbol in symbol_data_to_load:\n",
    "    print(\"Processing Symbol: \" + symbol)\n",
    "    temp_df = pd.read_csv(\"data/\" + symbol + \".csv\")\n",
    "    temp_df[\"Volume_Millions\"] = temp_df[\"Volume\"] / 1000000.0\n",
    "\n",
    "    # Add new column with symbol name to distinguish in final dataframe\n",
    "    temp_df[\"Symbol\"] = symbol\n",
    "    list_of_df.append(temp_df)\n",
    "\n",
    "# used a line break at the end of this string for aesthetics\n",
    "print(\" --- Complete loop over symbols --- \\n\")\n",
    "\n",
    "# Combine into a single DataFrame by using concat\n",
    "print(\"Aggregating Data\")\n",
    "agg_df = pd.concat(list_of_df, axis=0)\n",
    "\n",
    "# Add salient statistics for this return and volatility analysis\n",
    "print(\"Calculating Salient Features\")\n",
    "agg_df[\"VolStat\"] = (agg_df[\"High\"] - agg_df[\"Low\"]) / agg_df[\"Open\"]\n",
    "agg_df[\"Return\"] = (agg_df[\"Close\"] / agg_df[\"Open\"]) - 1.0\n",
    "\n",
    "print(\"agg_df DataFrame shape (rows, columns): \")\n",
    "print(agg_df.shape)\n",
    "\n",
    "print(\"Head of agg_df DataFrame: \")\n",
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the `for` loop, we've aggregated and added the relevant features we identified in the previous section. We then printed the head of the aggregated DataFrame to have a peek at the format of the data, and we've also printed the shape of the DataFrame. This is to sanity check that our final DataFrame is roughly what we expect. Notice the aggregated DataFrame has the same number of columns as the original single stock (D) data, however the number of rows have increased five-fold. This makes sense, because each additional symbol contains 1259 data entries, so five symbols leads to a total of ```1259*5 = 6295``` rows. So, this passes our sanity check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we want to reverse this process and extract the data relevant to a single stock symbol from the aggregated DataFrame ```agg_df```, we can do so using the ```==``` operator, which returns True when two objects contain the same value, and False otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Volume_Millions</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>VolStat</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-28</td>\n",
       "      <td>73.309998</td>\n",
       "      <td>74.480003</td>\n",
       "      <td>73.230003</td>\n",
       "      <td>74.389999</td>\n",
       "      <td>59.266285</td>\n",
       "      <td>3281100</td>\n",
       "      <td>3.2811</td>\n",
       "      <td>DUK</td>\n",
       "      <td>0.017051</td>\n",
       "      <td>0.014732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-29</td>\n",
       "      <td>74.400002</td>\n",
       "      <td>74.480003</td>\n",
       "      <td>73.760002</td>\n",
       "      <td>73.980003</td>\n",
       "      <td>58.939648</td>\n",
       "      <td>2236300</td>\n",
       "      <td>2.2363</td>\n",
       "      <td>DUK</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>-0.005645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>74.029999</td>\n",
       "      <td>74.199997</td>\n",
       "      <td>72.580002</td>\n",
       "      <td>73.050003</td>\n",
       "      <td>58.198696</td>\n",
       "      <td>2782200</td>\n",
       "      <td>2.7822</td>\n",
       "      <td>DUK</td>\n",
       "      <td>0.021883</td>\n",
       "      <td>-0.013238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>72.610001</td>\n",
       "      <td>73.099998</td>\n",
       "      <td>72.059998</td>\n",
       "      <td>72.129997</td>\n",
       "      <td>57.465740</td>\n",
       "      <td>3249000</td>\n",
       "      <td>3.2490</td>\n",
       "      <td>DUK</td>\n",
       "      <td>0.014323</td>\n",
       "      <td>-0.006611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>72.239998</td>\n",
       "      <td>73.370003</td>\n",
       "      <td>72.150002</td>\n",
       "      <td>72.940002</td>\n",
       "      <td>58.111061</td>\n",
       "      <td>3960200</td>\n",
       "      <td>3.9602</td>\n",
       "      <td>DUK</td>\n",
       "      <td>0.016888</td>\n",
       "      <td>0.009690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close   Volume  \\\n",
       "0  2014-07-28  73.309998  74.480003  73.230003  74.389999  59.266285  3281100   \n",
       "1  2014-07-29  74.400002  74.480003  73.760002  73.980003  58.939648  2236300   \n",
       "2  2014-07-30  74.029999  74.199997  72.580002  73.050003  58.198696  2782200   \n",
       "3  2014-07-31  72.610001  73.099998  72.059998  72.129997  57.465740  3249000   \n",
       "4  2014-08-01  72.239998  73.370003  72.150002  72.940002  58.111061  3960200   \n",
       "\n",
       "   Volume_Millions Symbol   VolStat    Return  \n",
       "0           3.2811    DUK  0.017051  0.014732  \n",
       "1           2.2363    DUK  0.009677 -0.005645  \n",
       "2           2.7822    DUK  0.021883 -0.013238  \n",
       "3           3.2490    DUK  0.014323 -0.006611  \n",
       "4           3.9602    DUK  0.016888  0.009690  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_DUK_df = agg_df[agg_df[\"Symbol\"] == \"DUK\"]\n",
    "symbol_DUK_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the code block above, we've filtered out the rows that correspond to each symbol. Namely,\n",
    "\n",
    "```python\n",
    "agg_df['Symbol'] == 'DUK'\n",
    "```\n",
    "returns a boolean series of the same number of rows of ```agg_df```, where each value is True or False depending on whether a specific row's ```Symbol``` value is equal to ```'DUK'```.\n",
    "\n",
    "This row extraction technique will be useful to us later in this case when we perform analyses on each individual stock symbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "\n",
    "If we added the number of rows together from the five DataFrames, ```D_df```,```NEE_df```,```EXC_df```,```SO_df```, and ```DUK_df```, we'd arrive at the same number of rows as ```agg_df```: 6295 rows. If we instead used the ```!=``` operator in the five lines where we filter out each symbol, how many rows would we have if we sum all the rows in the five new DataFrames?\n",
    "\n",
    "(a) 31475\n",
    "\n",
    "(b) 12590\n",
    "\n",
    "(c) 25180\n",
    "\n",
    "(d) 6295\n",
    "\n",
    "**Answer.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25180\n"
     ]
    }
   ],
   "source": [
    "X = 0\n",
    "for Symbol in symbol_data_to_load:\n",
    "    symbol_df = agg_df[agg_df[\"Symbol\"] != Symbol]\n",
    "    X = len(symbol_df) + X\n",
    "    \n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: \n",
    "\n",
    "Write code to write a `for` loop to loop through each of the five symbols, extract only the rows corresponding to each symbol, and calculate and print the average ```VolStat``` value for each of the five symbols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol:  D  Average VolStat=  0.01\n",
      "Symbol:  EXC  Average VolStat=  0.02\n",
      "Symbol:  NEE  Average VolStat=  0.01\n",
      "Symbol:  SO  Average VolStat=  0.01\n",
      "Symbol:  DUK  Average VolStat=  0.01\n"
     ]
    }
   ],
   "source": [
    "m = 0\n",
    "for Symbol in symbol_data_to_load:\n",
    "    symbol_df = agg_df[agg_df[\"Symbol\"] == Symbol]\n",
    "    m = symbol_df['VolStat'].mean()\n",
    "    print(\"Symbol: \",Symbol,\" Average VolStat= \", round(m,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing each stock's volatility levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```pandas``` offers the ability to group related rows of DataFrames according to the values of other rows. This useful feature is accomplished using the [groupby()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) method.  Let's take a look and see how this can be used to group rows so that each group corresponds to a single stock symbol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000020111E3CB70>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the groupby() method, notice a DataFrameGroupBy object is returned\n",
    "agg_df.groupby('Symbol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here, the ```DataFrameGroupBy``` object can be most readily thought of as containing a DataFrame object for every group (in this case, a DataFrame object for each symbol). Specifically, each item of the object is a tuple, containing the group identifier (in this case the Symbol), and the corresponding rows of the DataFrame that have that Symbol).\n",
    "\n",
    "Fortunately, ```pandas``` allows you to iterate over the `groupby()` object to see what's inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ Loop Begins ------ \n",
      "<class 'tuple'>\n",
      "D\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume  \\\n",
      "0  2014-07-28  69.750000  71.059998  69.750000  70.879997  57.963978  1806400   \n",
      "1  2014-07-29  70.669998  70.980003  69.930000  69.930000  57.187099  2231100   \n",
      "2  2014-07-30  70.000000  70.660004  68.400002  68.970001  56.402020  2588900   \n",
      "3  2014-07-31  68.629997  68.849998  67.580002  67.639999  55.314388  3266900   \n",
      "4  2014-08-01  67.330002  68.410004  67.220001  67.589996  55.273487  2601800   \n",
      "\n",
      "   Volume_Millions Symbol   VolStat    Return  \n",
      "0           1.8064      D  0.018781  0.016201  \n",
      "1           2.2311      D  0.014858 -0.010471  \n",
      "2           2.5889      D  0.032286 -0.014714  \n",
      "3           3.2669      D  0.018505 -0.014425  \n",
      "4           2.6018      D  0.017674  0.003861  \n",
      " ------ Loop Ends ------ \n",
      " ------ Loop Begins ------ \n",
      "<class 'tuple'>\n",
      "DUK\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume  \\\n",
      "0  2014-07-28  73.309998  74.480003  73.230003  74.389999  59.266285  3281100   \n",
      "1  2014-07-29  74.400002  74.480003  73.760002  73.980003  58.939648  2236300   \n",
      "2  2014-07-30  74.029999  74.199997  72.580002  73.050003  58.198696  2782200   \n",
      "3  2014-07-31  72.610001  73.099998  72.059998  72.129997  57.465740  3249000   \n",
      "4  2014-08-01  72.239998  73.370003  72.150002  72.940002  58.111061  3960200   \n",
      "\n",
      "   Volume_Millions Symbol   VolStat    Return  \n",
      "0           3.2811    DUK  0.017051  0.014732  \n",
      "1           2.2363    DUK  0.009677 -0.005645  \n",
      "2           2.7822    DUK  0.021883 -0.013238  \n",
      "3           3.2490    DUK  0.014323 -0.006611  \n",
      "4           3.9602    DUK  0.016888  0.009690  \n",
      " ------ Loop Ends ------ \n",
      " ------ Loop Begins ------ \n",
      "<class 'tuple'>\n",
      "EXC\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume  \\\n",
      "0  2014-07-28  31.410000  32.130001  31.379999  31.950001  26.442406  5683400   \n",
      "1  2014-07-29  31.940001  32.049999  31.430000  31.469999  26.045147  6292800   \n",
      "2  2014-07-30  31.629999  31.660000  30.850000  31.010000  25.664442  7976600   \n",
      "3  2014-07-31  30.930000  31.490000  30.799999  31.080000  25.722378  9236100   \n",
      "4  2014-08-01  31.139999  32.080002  31.100000  31.540001  26.103081  9734300   \n",
      "\n",
      "   Volume_Millions Symbol   VolStat    Return  \n",
      "0           5.6834    EXC  0.023878  0.017192  \n",
      "1           6.2928    EXC  0.019411 -0.014715  \n",
      "2           7.9766    EXC  0.025609 -0.019602  \n",
      "3           9.2361    EXC  0.022308  0.004850  \n",
      "4           9.7343    EXC  0.031471  0.012845  \n",
      " ------ Loop Ends ------ \n",
      " ------ Loop Begins ------ \n",
      "<class 'tuple'>\n",
      "NEE\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume  \\\n",
      "0  2014-07-28  98.470001  99.760002  98.099998  99.580002  85.106087  1643000   \n",
      "1  2014-07-29  99.029999  99.389999  97.300003  98.400002  84.097595  1942500   \n",
      "2  2014-07-30  98.160004  98.500000  95.760002  96.339996  82.337006  2844100   \n",
      "3  2014-07-31  95.639999  95.980003  93.800003  93.889999  80.243126  2725200   \n",
      "4  2014-08-01  93.500000  94.919998  93.279999  93.820000  80.183289  2514400   \n",
      "\n",
      "   Volume_Millions Symbol   VolStat    Return  \n",
      "0           1.6430    NEE  0.016858  0.011272  \n",
      "1           1.9425    NEE  0.021105 -0.006362  \n",
      "2           2.8441    NEE  0.027914 -0.018541  \n",
      "3           2.7252    NEE  0.022794 -0.018298  \n",
      "4           2.5144    NEE  0.017540  0.003422  \n",
      " ------ Loop Ends ------ \n",
      " ------ Loop Begins ------ \n",
      "<class 'tuple'>\n",
      "SO\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume  \\\n",
      "0  2014-07-28  44.619999  45.430000  44.619999  45.360001  35.349178  5568900   \n",
      "1  2014-07-29  45.470001  45.470001  44.669998  44.860001  34.959522  5499600   \n",
      "2  2014-07-30  45.000000  45.000000  44.009998  44.380001  34.585461  6945200   \n",
      "3  2014-07-31  43.889999  43.889999  43.220001  43.290001  34.139881  5675300   \n",
      "4  2014-08-01  43.340000  43.830002  43.250000  43.320000  34.163548  4193700   \n",
      "\n",
      "   Volume_Millions Symbol   VolStat    Return  \n",
      "0           5.5689     SO  0.018153  0.016585  \n",
      "1           5.4996     SO  0.017594 -0.013415  \n",
      "2           6.9452     SO  0.022000 -0.013778  \n",
      "3           5.6753     SO  0.015265 -0.013670  \n",
      "4           4.1937     SO  0.013383 -0.000461  \n",
      " ------ Loop Ends ------ \n"
     ]
    }
   ],
   "source": [
    "grp_obj = agg_df.groupby(\"Symbol\")  # Group data in agg_df by Symbol\n",
    "\n",
    "# Loop through groups\n",
    "for item in grp_obj:\n",
    "    print(\" ------ Loop Begins ------ \")\n",
    "    print(type(item))  # Showing type of the item in grp_obj\n",
    "    print(item[0])  # Symbol\n",
    "    print(item[1].head())  # DataFrame with data for the Symbol\n",
    "    print(\" ------ Loop Ends ------ \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine the ```pd.groupby()``` method with the ```describe()``` method and apply it to each symbol to analyze the distribution of volatility related features for each symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Symbol:  D\n",
      "           VolStat\n",
      "count  1259.000000\n",
      "mean      0.014836\n",
      "std       0.006548\n",
      "min       0.003640\n",
      "25%       0.010246\n",
      "50%       0.013528\n",
      "75%       0.017920\n",
      "max       0.062350\n",
      "------Symbol:  DUK\n",
      "           VolStat\n",
      "count  1259.000000\n",
      "mean      0.014534\n",
      "std       0.007047\n",
      "min       0.003548\n",
      "25%       0.010075\n",
      "50%       0.012922\n",
      "75%       0.017653\n",
      "max       0.117492\n",
      "------Symbol:  EXC\n",
      "           VolStat\n",
      "count  1259.000000\n",
      "mean      0.017722\n",
      "std       0.008129\n",
      "min       0.005230\n",
      "25%       0.011868\n",
      "50%       0.015931\n",
      "75%       0.021752\n",
      "max       0.093156\n",
      "------Symbol:  NEE\n",
      "           VolStat\n",
      "count  1259.000000\n",
      "mean      0.014881\n",
      "std       0.006544\n",
      "min       0.004454\n",
      "25%       0.010309\n",
      "50%       0.013439\n",
      "75%       0.017700\n",
      "max       0.048495\n",
      "------Symbol:  SO\n",
      "           VolStat\n",
      "count  1259.000000\n",
      "mean      0.014065\n",
      "std       0.006109\n",
      "min       0.003960\n",
      "25%       0.009786\n",
      "50%       0.012858\n",
      "75%       0.016865\n",
      "max       0.051847\n"
     ]
    }
   ],
   "source": [
    "grp_obj = agg_df.groupby(\"Symbol\")  # Group data in agg_df by Symbol\n",
    "\n",
    "# Loop through groups\n",
    "for item in grp_obj:\n",
    "    print(\"------Symbol: \", item[0])\n",
    "    grp_df = item[1]\n",
    "    relevant_df = grp_df[[\"VolStat\"]]\n",
    "    print(relevant_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One immediate observation of note is that the volatility level on any given day can vary widely. This is evident from the wide spread between the minimum and maximum ```VolStat``` levels seen using the ```describe()``` method. For example, stock symbol D has a minimum ```VolStat``` value of 0.003640, while its maximum ```VolStat``` value is 0.062350. That's more than a 10x increase in the value of ```VolStat```!\n",
    "\n",
    "While this is great to see, there is a more powerful way to display this data in `pandas`. We can call the ```describe()``` method directly on the ```DataFrameGroupBy``` object. This one line allows you to avoid having to write a `for` loop every time you'd like to summarize data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">VolStat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>1259.0</td>\n",
       "      <td>0.014836</td>\n",
       "      <td>0.006548</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.010246</td>\n",
       "      <td>0.013528</td>\n",
       "      <td>0.017920</td>\n",
       "      <td>0.062350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUK</th>\n",
       "      <td>1259.0</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007047</td>\n",
       "      <td>0.003548</td>\n",
       "      <td>0.010075</td>\n",
       "      <td>0.012922</td>\n",
       "      <td>0.017653</td>\n",
       "      <td>0.117492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXC</th>\n",
       "      <td>1259.0</td>\n",
       "      <td>0.017722</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>0.005230</td>\n",
       "      <td>0.011868</td>\n",
       "      <td>0.015931</td>\n",
       "      <td>0.021752</td>\n",
       "      <td>0.093156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEE</th>\n",
       "      <td>1259.0</td>\n",
       "      <td>0.014881</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.013439</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.048495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SO</th>\n",
       "      <td>1259.0</td>\n",
       "      <td>0.014065</td>\n",
       "      <td>0.006109</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0.012858</td>\n",
       "      <td>0.016865</td>\n",
       "      <td>0.051847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       VolStat                                                              \\\n",
       "         count      mean       std       min       25%       50%       75%   \n",
       "Symbol                                                                       \n",
       "D       1259.0  0.014836  0.006548  0.003640  0.010246  0.013528  0.017920   \n",
       "DUK     1259.0  0.014534  0.007047  0.003548  0.010075  0.012922  0.017653   \n",
       "EXC     1259.0  0.017722  0.008129  0.005230  0.011868  0.015931  0.021752   \n",
       "NEE     1259.0  0.014881  0.006544  0.004454  0.010309  0.013439  0.017700   \n",
       "SO      1259.0  0.014065  0.006109  0.003960  0.009786  0.012858  0.016865   \n",
       "\n",
       "                  \n",
       "             max  \n",
       "Symbol            \n",
       "D       0.062350  \n",
       "DUK     0.117492  \n",
       "EXC     0.093156  \n",
       "NEE     0.048495  \n",
       "SO      0.051847  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VolStat\n",
    "agg_df[[\"Symbol\", \"VolStat\"]].groupby(\"Symbol\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is identical to the data previously outputted using the `for` loop approach. The difference is that utilizing the features of the ```DataFrameGroupBy``` object allows for easy coding, fast results, and a clean output. This illustrates the power of using the ```pd.groupby()``` method: generating statistics for groups of interest in your data is straightforward and efficient to code.\n",
    "\n",
    "You'll notice this pattern a lot as you gain more familiarity with Python and data analysis. There are many ways to solve a problem, but often one way is substantially more efficient, both in terms of run time and in terms of lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4:\n",
    "\n",
    "What are some insights you can draw from the ```VolStat``` summary statistics in terms of volatility levels?\n",
    "\n",
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant difference between the mean of the index EXC and other items means, this Symbol should be study due to their values normaly are bigger than the other symbol. Besides the higgest max VolStat, came from the DUK, then this item should be analyzed perhaps it could be an out-laier point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5:\n",
    "\n",
    "Using ```agg_df``` and a `for` loop, write a script to determine the mean value of ```VolStat``` for each symbol by year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n",
      "       VolStat\n",
      "year          \n",
      "2014  0.016510\n",
      "2015  0.015748\n",
      "2016  0.015051\n",
      "2017  0.011246\n",
      "2018  0.016678\n",
      "2019  0.014631\n",
      "EXC\n",
      "       VolStat\n",
      "year          \n",
      "2014  0.020166\n",
      "2015  0.021383\n",
      "2016  0.019270\n",
      "2017  0.013746\n",
      "2018  0.017106\n",
      "2019  0.014720\n",
      "NEE\n",
      "       VolStat\n",
      "year          \n",
      "2014  0.015843\n",
      "2015  0.016274\n",
      "2016  0.015805\n",
      "2017  0.011648\n",
      "2018  0.016043\n",
      "2019  0.013692\n",
      "SO\n",
      "       VolStat\n",
      "year          \n",
      "2014  0.013988\n",
      "2015  0.014625\n",
      "2016  0.014233\n",
      "2017  0.010955\n",
      "2018  0.016859\n",
      "2019  0.013395\n",
      "DUK\n",
      "       VolStat\n",
      "year          \n",
      "2014  0.014592\n",
      "2015  0.016215\n",
      "2016  0.015841\n",
      "2017  0.010032\n",
      "2018  0.016472\n",
      "2019  0.013723\n"
     ]
    }
   ],
   "source": [
    "agg_df['Date'] = pd.to_datetime(agg_df['Date'])\n",
    "agg_df['year'] = pd.DatetimeIndex(agg_df['Date']).year\n",
    "for Symbol in symbol_data_to_load:\n",
    "    y = agg_df[agg_df[\"Symbol\"] == Symbol]\n",
    "    mlist = y[[\"year\", \"VolStat\"]].groupby(\"year\").mean()\n",
    "    print(Symbol)\n",
    "    print(mlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              VolStat\n",
      "Symbol year          \n",
      "D      2014  0.016510\n",
      "       2015  0.015748\n",
      "       2016  0.015051\n",
      "       2017  0.011246\n",
      "       2018  0.016678\n",
      "       2019  0.014631\n",
      "DUK    2014  0.014592\n",
      "       2015  0.016215\n",
      "       2016  0.015841\n",
      "       2017  0.010032\n",
      "       2018  0.016472\n",
      "       2019  0.013723\n",
      "EXC    2014  0.020166\n",
      "       2015  0.021383\n",
      "       2016  0.019270\n",
      "       2017  0.013746\n",
      "       2018  0.017106\n",
      "       2019  0.014720\n",
      "NEE    2014  0.015843\n",
      "       2015  0.016274\n",
      "       2016  0.015805\n",
      "       2017  0.011648\n",
      "       2018  0.016043\n",
      "       2019  0.013692\n",
      "SO     2014  0.013988\n",
      "       2015  0.014625\n",
      "       2016  0.014233\n",
      "       2017  0.010955\n",
      "       2018  0.016859\n",
      "       2019  0.013395\n"
     ]
    }
   ],
   "source": [
    "agg_df['Date'] = pd.to_datetime(agg_df['Date'])\n",
    "agg_df['year'] = pd.DatetimeIndex(agg_df['Date']).year\n",
    "gp = agg_df[[\"Symbol\",\"year\",\"VolStat\"]].groupby([\"Symbol\",\"year\"]).mean()\n",
    "print(gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling data points as high or low volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've determined that the volatility levels of each stock can vary widely, the next logical step is to group periods of high and low volatility so that we can then look at how volume differs between those time periods.\n",
    "\n",
    "However, we don't currently have a column that identifies when volatility is high and when it is low. Therefore, we must create a new column called ```VolLevel``` using some volatility threshold. For example, we'd like to have a new column value determined by:\n",
    "\n",
    "```\n",
    "if VolStat > threshold:\n",
    "    VolLevel = 'HIGH'\n",
    "else:\n",
    "    VolLevel = 'LOW'\n",
    "```\n",
    "\n",
    "Here we will define low volatility levels by any ```VolStat``` below the 50th percentile (i.e. below the median level of volatility for that symbol). Each percentile value must be calculated by symbol to ensure that each symbol is individually analyzed.\n",
    "\n",
    "Let's take a look how we can accomplish this task using ```groupby()``` functionality and the ```quantile()``` method, which returns the percentile for a given series of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol\n",
      "D      0.013528\n",
      "DUK    0.012922\n",
      "EXC    0.015931\n",
      "NEE    0.013439\n",
      "SO     0.012858\n",
      "Name: VolStat, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Determine lower thresholds for volatility for each symbol\n",
    "volstat_thresholds = agg_df.groupby(\"Symbol\")[\"VolStat\"].quantile(0.5)  # 50th percentile (median)\n",
    "print(volstat_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we'd like to label periods of high and low volatility by symbol, we will make use of the [np.where()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html) method in the ```numpy``` library. This method takes an input and checks a logical condition: if the condition is true, it will return its second argument, whereas if the condition is false, it will return its third argument. This is very similar to how Microsoft Excel's ```IFERROR()``` method works (helpful to think of it this way for those familiar with Excel). Let's loop through each symbol and label each day as either high and low volatility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining stock symbols\n",
      " --- Loop over symbols --- \n",
      "Labelling Volatility regime for Symbol: D\n",
      "Labelling Volatility regime for Symbol: EXC\n",
      "Labelling Volatility regime for Symbol: NEE\n",
      "Labelling Volatility regime for Symbol: SO\n",
      "Labelling Volatility regime for Symbol: DUK\n",
      " --- Completed loop over symbols --- \n",
      "Aggregating data\n"
     ]
    }
   ],
   "source": [
    "# Loop through symbols\n",
    "print(\"Defining stock symbols\")\n",
    "list_of_symbols = [\"D\", \"EXC\", \"NEE\", \"SO\", \"DUK\"]\n",
    "list_of_df = []\n",
    "\n",
    "# Loop over all symbols\n",
    "print(\" --- Loop over symbols --- \")\n",
    "for i in symbol_data_to_load:\n",
    "    print(\"Labelling Volatility regime for Symbol: \" + i)\n",
    "    temp_df = agg_df[agg_df[\"Symbol\"] == i].copy()  # make a copy of the dataframe to ensure not affecting agg_df\n",
    "    volstat_t = volstat_thresholds.loc[i]\n",
    "    #Funtion to labeling\n",
    "    temp_df[\"VolLevel\"] = np.where(temp_df[\"VolStat\"] < volstat_t, \"LOW\", \"HIGH\")  # Volatility regime label\n",
    "    list_of_df.append(temp_df)\n",
    "\n",
    "print(\" --- Completed loop over symbols --- \")\n",
    "\n",
    "print(\"Aggregating data\")\n",
    "labeled_df = pd.concat(list_of_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Volume_Millions</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>VolStat</th>\n",
       "      <th>Return</th>\n",
       "      <th>year</th>\n",
       "      <th>VolLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-28</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>71.059998</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>70.879997</td>\n",
       "      <td>57.963978</td>\n",
       "      <td>1806400</td>\n",
       "      <td>1.8064</td>\n",
       "      <td>D</td>\n",
       "      <td>0.018781</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>2014</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-29</td>\n",
       "      <td>70.669998</td>\n",
       "      <td>70.980003</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>57.187099</td>\n",
       "      <td>2231100</td>\n",
       "      <td>2.2311</td>\n",
       "      <td>D</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>-0.010471</td>\n",
       "      <td>2014</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.660004</td>\n",
       "      <td>68.400002</td>\n",
       "      <td>68.970001</td>\n",
       "      <td>56.402020</td>\n",
       "      <td>2588900</td>\n",
       "      <td>2.5889</td>\n",
       "      <td>D</td>\n",
       "      <td>0.032286</td>\n",
       "      <td>-0.014714</td>\n",
       "      <td>2014</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>68.629997</td>\n",
       "      <td>68.849998</td>\n",
       "      <td>67.580002</td>\n",
       "      <td>67.639999</td>\n",
       "      <td>55.314388</td>\n",
       "      <td>3266900</td>\n",
       "      <td>3.2669</td>\n",
       "      <td>D</td>\n",
       "      <td>0.018505</td>\n",
       "      <td>-0.014425</td>\n",
       "      <td>2014</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>67.330002</td>\n",
       "      <td>68.410004</td>\n",
       "      <td>67.220001</td>\n",
       "      <td>67.589996</td>\n",
       "      <td>55.273487</td>\n",
       "      <td>2601800</td>\n",
       "      <td>2.6018</td>\n",
       "      <td>D</td>\n",
       "      <td>0.017674</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>2014</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Open       High        Low      Close  Adj Close   Volume  \\\n",
       "0 2014-07-28  69.750000  71.059998  69.750000  70.879997  57.963978  1806400   \n",
       "1 2014-07-29  70.669998  70.980003  69.930000  69.930000  57.187099  2231100   \n",
       "2 2014-07-30  70.000000  70.660004  68.400002  68.970001  56.402020  2588900   \n",
       "3 2014-07-31  68.629997  68.849998  67.580002  67.639999  55.314388  3266900   \n",
       "4 2014-08-01  67.330002  68.410004  67.220001  67.589996  55.273487  2601800   \n",
       "\n",
       "   Volume_Millions Symbol   VolStat    Return  year VolLevel  \n",
       "0           1.8064      D  0.018781  0.016201  2014     HIGH  \n",
       "1           2.2311      D  0.014858 -0.010471  2014     HIGH  \n",
       "2           2.5889      D  0.032286 -0.014714  2014     HIGH  \n",
       "3           3.2669      D  0.018505 -0.014425  2014     HIGH  \n",
       "4           2.6018      D  0.017674  0.003861  2014     HIGH  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now added a ```VolLevel``` column that identifies whether each symbol is in a period of high or low volatility on any given day. Since we know that the bank will require higher trading volume in order to transact in periods of high volatility, let's now take a look at the average daily traded volume for high volatility vs. low volatility days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is daily trading volume affected by the level of volatility?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore the relationship between volatility level and daily trading volume, let's group by ```VolLevel``` and take a look at the average ```Volume``` for the high and low volatility groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Volume_Millions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbol</th>\n",
       "      <th>VolLevel</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">D</th>\n",
       "      <th>HIGH</th>\n",
       "      <td>3.538901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOW</th>\n",
       "      <td>2.636641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DUK</th>\n",
       "      <th>HIGH</th>\n",
       "      <td>3.760172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOW</th>\n",
       "      <td>2.825710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">EXC</th>\n",
       "      <th>HIGH</th>\n",
       "      <td>7.090384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOW</th>\n",
       "      <td>5.031123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">NEE</th>\n",
       "      <th>HIGH</th>\n",
       "      <td>2.361096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOW</th>\n",
       "      <td>1.707347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SO</th>\n",
       "      <th>HIGH</th>\n",
       "      <td>6.148537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOW</th>\n",
       "      <td>4.417179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Volume_Millions\n",
       "Symbol VolLevel                 \n",
       "D      HIGH             3.538901\n",
       "       LOW              2.636641\n",
       "DUK    HIGH             3.760172\n",
       "       LOW              2.825710\n",
       "EXC    HIGH             7.090384\n",
       "       LOW              5.031123\n",
       "NEE    HIGH             2.361096\n",
       "       LOW              1.707347\n",
       "SO     HIGH             6.148537\n",
       "       LOW              4.417179"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.groupby([\"Symbol\", \"VolLevel\"])[[\"Volume_Millions\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6:\n",
    "\n",
    "What is an immediate trend you notice regarding the volatility regimes?\n",
    "\n",
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The volume in millions change depending if the vol level is HIGH or LOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: \n",
    "\n",
    "Write code to group time periods into low, medium, and high volatility regimes, where:\n",
    "\n",
    "```\n",
    "if VolStat > (75th percentile VolStat for given symbol):\n",
    "    VolLevel = 'HIGH'\n",
    "elif  VolStat > (25th percentile VolStat for given symbol):\n",
    "    VolLevel = 'MEDIUM'\n",
    "else:\n",
    "    VolLevel = 'LOW'\n",
    "```\n",
    "\n",
    "Output a ```final_df``` DataFrame output grouped by `Symbol`, showing the mean `Volume` for each `VolLevel` category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = []\n",
    "list_of_symbols = [\"D\", \"EXC\", \"NEE\", \"SO\", \"DUK\"]\n",
    "\n",
    "for S in list_of_symbols:\n",
    "    t = agg_df[agg_df[\"Symbol\"] == S].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, we use ```loc``` to index the DataFrame object. This is just one of many different ways to slice your DataFrame object. We recommend looking into [loc vs iloc](https://www.pythonprogramming.in/what-is-difference-between-iloc-and-loc-in-pandas.html) as both will be useful for all data scientists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing volatility across time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now satisfactorily answered our original question. However, you don't need to just analyze data in tabular format. Python contains functionality to allow you to analyze your data visually as well.\n",
    "\n",
    "We will use ```pandas``` functionality built on the standard Python plotting library [matplotlib](https://matplotlib.org/). Let's import the library and instruct Jupyter to display the plots inline (i.e. display the plots to the notebook screen so we can see them as we run the code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fundamental plotting library in Python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Instruct jupyter to plot in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we plot, we need to convert the ```Date``` column in ```agg_df``` to a ```datetime```-like object, Python's internal data representation of dates. ```pandas``` offers the [to_datetime()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) method to convert a string that represents a given date format into a ```datetime```-like object. We instruct ```pandas``` to use ```format='%Y-%m-%d'```, since our dates are in this format, where %Y indicates the numerical year, %m indicates the numerical month and %d indicates the numerical day. If our dates were in another format, we'd modify this input value appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert a string to a datetime\n",
    "agg_df[\"DateTime\"] = pd.to_datetime(agg_df[\"Date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "# Set index as DateTime for plotting purposes\n",
    "agg_df = agg_df.set_index([\"DateTime\"])\n",
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to look directly at volatility across time. Let's group by symbols and plot the ```VolStat``` value across time. Each symbol's time series will be labelled a different color by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at volatility regimes\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "agg_df.groupby(\"Symbol\")[\"VolStat\"].plot(\n",
    "    ax=ax, legend=True, title=\"Energy Sector Trends - VolStat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that periods of high volatility tend to \"clump\" together; that is, periods of high volatility are not uniformly and randomly distributed across time, but tend to occur in highly concentrated bursts. This is an interesting insight that we could not gain by only looking at the data in tabular format. In future cases, you will dig deeper into the numerous graphing capabilities of Python and how to integrate them into your data science workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8:\n",
    "\n",
    "Write a script to find and print the month that has the highest average daily trading volume for each symbol. Also include the average volume value corresponding to that month. For example, symbol D has its highest average daily trading volume of 6.437 million in December 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9:\n",
    "\n",
    "We have so far looked at volatility grouped by stock symbol or by year and month. As our data covers several years, it's also interesting to group the data by calendar month, ignoring the year component (e.g. averaging together all Januarys). This allows us to see if some points of the year, on average, are more susceptible to volatile trading patterns.\n",
    "\n",
    "Group the data by month (ignoring the year), and identify :\n",
    "\n",
    "* The month with, on average, the highest volatility\n",
    "* The month with, on average, the lowest volatility\n",
    "* Any general patterns that you notice over the whole year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10:\n",
    "\n",
    "The final point that we're interested in is looking at the days where:\n",
    "\n",
    "* The return is high\n",
    "* Trading volume is low\n",
    "\n",
    "This indicates days where the price moved substantially but without much changing hands.\n",
    "\n",
    "The thresholds that we are interested in are:\n",
    "* Low volume: any day with a trading volume in the bottom 25th percentile\n",
    "* High return: any day where the return is in the opt 75th percentile\n",
    "\n",
    "Write the code necessary to:\n",
    "* Calculate and add a \"High/Low\" variable for Volume Level (low is below 25th percentile)\n",
    "* Calculate and add a \"High/Low\" variable for Return (high is above 75th percentile)\n",
    "\n",
    "Describe what you see in terms of:\n",
    "* How many rows fall into our \"low volume\" definition?\n",
    "* How many rows fall into our \"high return\" definition?\n",
    "* How many rows fall into the combination of high return with low volume definition?\n",
    "* What are the 20 rows with the highest return but with low volume? What do you notice about these trades?\n",
    "\n",
    "(hint, you can use the [sort_values()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html) method in `pandas` to sort a DataFrame by a specific column.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Having completed the analysis of the energy sector stock data, we have identified a number of interesting patterns relating volatility to trading volume. Specifically, we found that periods of high volatility also exhibit very high volume. This trend is consistent across all symbols.\n",
    "\n",
    "We also saw that each stock exhibited \"volatility clustering\" â€“ periods of high volatility tend to be clumped together. Each of the stocks experienced high volatility at relatively similar times which suggests some broader market factor may be affecting the energy sector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this case, we've learned the foundations of the ```pandas``` library in Python. We now know how to:\n",
    "\n",
    "1. Read data from CSV files\n",
    "2. Aggregate and manipulate data using ```pandas```\n",
    "3. Analyze summary statistics and gather information from trends across time\n",
    "4. Use ```matplotlib``` to create plots for visual analysis\n",
    "\n",
    "Going forward, we will be consistently using ```pandas``` as a data analysis framework (along with other tools) to build more complex projects and solve critical business problems. It is critical you become as familiar with ```pandas``` as possible and it is imperative that you continue researching/investigating new components of this library after the completion of this program. What we have taught here are only the essential basics of `pandas`; there is still a vast amount of power to the library that you will discover and utilize later on in your development as a data professional.\n",
    "\n",
    "We highly recommend revisiting this case a few more times and going through it from beginning to end with no aid/answers. You should know the various DataFrame/Series methods we introduced here as well as how to carry out common operations on data, such as finding percentiles, before you consider yourself to have \"mastered\" this material."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
